"use strict";(globalThis.webpackChunkhumanoid_robot_book=globalThis.webpackChunkhumanoid_robot_book||[]).push([[54],{1782:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>t,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"ai-learning/index","title":"08 - AI and Machine Learning for Humanoids","description":"Artificial Intelligence (AI) and Machine Learning (ML) are rapidly transforming humanoid robotics, enabling robots to learn, adapt, and perform complex tasks with increasing autonomy. This chapter explores key AI/ML paradigms and their applications in humanoid systems.","source":"@site/docs/08-ai-learning/index.mdx","sourceDirName":"08-ai-learning","slug":"/ai-learning/","permalink":"/humanoid-robot-book/ai-learning/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"07 - Human-Robot Interaction (HRI)","permalink":"/humanoid-robot-book/human-robot-interaction/"},"next":{"title":"ROS Installation and Basic Setup Tutorial","permalink":"/humanoid-robot-book/appendices/ros-setup"}}');var o=i(4848),r=i(8453);const t={},s="08 - AI and Machine Learning for Humanoids",l={},c=[{value:"Reinforcement Learning for Motor Control",id:"reinforcement-learning-for-motor-control",level:2},{value:"Deep Learning for Perception",id:"deep-learning-for-perception",level:2},{value:"Adaptive Control and Learning from Demonstration",id:"adaptive-control-and-learning-from-demonstration",level:2}];function d(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"08---ai-and-machine-learning-for-humanoids",children:"08 - AI and Machine Learning for Humanoids"})}),"\n",(0,o.jsx)(e.p,{children:"Artificial Intelligence (AI) and Machine Learning (ML) are rapidly transforming humanoid robotics, enabling robots to learn, adapt, and perform complex tasks with increasing autonomy. This chapter explores key AI/ML paradigms and their applications in humanoid systems."}),"\n",(0,o.jsx)(e.h2,{id:"reinforcement-learning-for-motor-control",children:"Reinforcement Learning for Motor Control"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Reinforcement Learning (RL)"})," is a paradigm where an agent learns to make decisions by performing actions in an environment to maximize a cumulative reward. It's particularly well-suited for teaching humanoid robots complex motor skills."]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"How it Works:"})," The robot (agent) observes its state (e.g., joint angles, velocities, IMU data), takes an action (e.g., applies torques to joints), and receives a reward or penalty from the environment. Through trial and error, the robot learns an optimal policy (a mapping from states to actions)."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Applications in Humanoids:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Gait Optimization:"})," Learning efficient and stable walking patterns."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Dynamic Balancing:"})," Recovering from pushes or maintaining balance on uneven terrain."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Manipulation Skills:"})," Learning to grasp, lift, and place objects with dexterity."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Algorithms:"})," Popular RL algorithms include Q-learning, Deep Q-Networks (DQN), Proximal Policy Optimization (PPO), and Soft Actor-Critic (SAC). These often use deep neural networks (Deep Reinforcement Learning) to handle high-dimensional state and action spaces."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"deep-learning-for-perception",children:"Deep Learning for Perception"}),"\n",(0,o.jsx)(e.p,{children:"Deep learning, a subset of machine learning using artificial neural networks with many layers, has revolutionized robot perception, allowing humanoids to make sense of rich sensory data."}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Convolutional Neural Networks (CNNs):"})," Primarily used for image and video processing.","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Object Detection:"})," Identifying and localizing objects in the robot's visual field (e.g., using YOLO, Faster R-CNN)."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Object Recognition/Classification:"})," Categorizing detected objects."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Semantic Segmentation:"})," Labeling each pixel in an image with a corresponding class (e.g., ground, sky, human, chair)."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Recurrent Neural Networks (RNNs) / Transformers:"})," Used for processing sequential data.","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Speech Recognition:"})," Converting spoken commands into text."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Human Pose Estimation:"})," Tracking human movements over time."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Applications:"})," Enhanced visual navigation, facial recognition, understanding human gestures, and interpreting complex scenes."]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"TensorFlow/PyTorch Example: Simple Image Classifier (Conceptual)"})}),"\n",(0,o.jsx)(e.p,{children:"While a full humanoid perception system is complex, a basic image classifier demonstrates the core idea of deep learning for perception. This conceptual snippet shows a simple CNN for classifying images, which could be extended for object recognition in a robot."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# --- 1. Define the CNN Model (Conceptual) ---\ndef create_simple_cnn(input_shape, num_classes):\n    model = models.Sequential([\n        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(64, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(64, (3, 3), activation='relu'),\n        layers.Flatten(),\n        layers.Dense(64, activation='relu'),\n        layers.Dense(num_classes, activation='softmax') # For multi-class classification\n    ])\n    return model\n\n# --- 2. Example Usage (Conceptual) ---\n# Assuming you have image data (e.g., `X_train`, `y_train`)\n# For a real robot, `input_shape` would depend on your camera resolution (height, width, channels)\n\n# Example: 64x64 RGB images, 10 categories of objects\ninput_shape = (64, 64, 3)\nnum_classes = 10\n\nmodel = create_simple_cnn(input_shape, num_classes)\nmodel.summary()\n\n# --- 3. Compile and Train (Conceptual) ---\n# In a real scenario, you'd have actual data loading and training loops\n# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n# model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n\n# --- 4. Inference (Conceptual) ---\n# Once trained, the robot would pass new camera images to the model for prediction\n# example_image = np.random.rand(1, 64, 64, 3) # Simulate a new image\n# prediction = model.predict(example_image)\n# predicted_class = np.argmax(prediction)\n# print(f\"Detected object class: {predicted_class}\")\n"})}),"\n",(0,o.jsx)(e.h2,{id:"adaptive-control-and-learning-from-demonstration",children:"Adaptive Control and Learning from Demonstration"}),"\n",(0,o.jsx)(e.p,{children:"Humanoid robots often need to adapt to changing conditions or learn new skills efficiently."}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Adaptive Control:"})," Control systems that can adjust their parameters automatically in response to changes in the robot's own dynamics (e.g., carrying a heavy load) or the environment (e.g., walking on slippery surfaces). This allows for robust performance in varied situations."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Learning from Demonstration (LfD) / Imitation Learning:"})," A powerful paradigm where a robot learns a skill by observing a human performing it. Instead of explicit programming, the robot mimics demonstrated trajectories or policies.","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.em,{children:"Methods:"})," Can involve recording human joint movements, end-effector trajectories, or even sensory-motor mappings."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.em,{children:"Benefits:"})," Significantly reduces programming effort for complex tasks, making it easier to transfer skills to robots."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"AI and ML techniques are not just enhancements but foundational pillars for building truly intelligent, adaptable, and autonomous humanoid robots capable of operating in unstructured human environments."})]})}function m(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>t,x:()=>s});var a=i(6540);const o={},r=a.createContext(o);function t(n){const e=a.useContext(r);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:t(n.components),a.createElement(r.Provider,{value:e},n.children)}}}]);