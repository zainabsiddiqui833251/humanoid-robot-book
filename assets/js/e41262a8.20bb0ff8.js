"use strict";(globalThis.webpackChunkhumanoid_robot_book=globalThis.webpackChunkhumanoid_robot_book||[]).push([[854],{8453:(n,e,o)=>{o.d(e,{R:()=>r,x:()=>s});var t=o(6540);const a={},i=t.createContext(a);function r(n){const e=t.useContext(i);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:r(n.components),t.createElement(i.Provider,{value:e},n.children)}},8865:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"actuation-control/index","title":"05 - Actuation and Control","description":"The ability of a humanoid robot to move gracefully, maintain balance, and interact with its environment stems from sophisticated actuation and control systems. This chapter dives into the mechanisms that translate high-level commands into physical motion.","source":"@site/docs/05-actuation-control/index.mdx","sourceDirName":"05-actuation-control","slug":"/actuation-control/","permalink":"/humanoid-robot-book/docs/actuation-control/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"04 - Sensors and Perception","permalink":"/humanoid-robot-book/docs/sensors-perception/"},"next":{"title":"06 - Path Planning and Navigation\\\\n\\\\nFor a humanoid robot to operate effectively in complex and dynamic environments, it must be able to plan its movements and navigate safely. This chapter explores the core concepts and algorithms behind path planning and navigation in robotics.\\\\n\\\\n## Collision Avoidance\\\\n\\\\nOne of the primary concerns in robot motion is preventing collisions with obstacles in the environment or even with the robot\\\\\'s own body parts. Collision avoidance strategies can be proactive (planning collision-free paths) or reactive (adjusting motion in real-time).\\\\n\\\\n*   **Occupancy Grids:** A common way to represent the environment, where space is discretized into cells, each indicating the probability of being occupied by an obstacle. Sensors (like lidar or depth cameras) update these grids.\\\\n*   **Configuration Space (C-Space):** Transforms the robot\\\\\'s physical space into a higher-dimensional space where the robot is represented as a point, and obstacles grow correspondingly. Planning in C-space simplifies collision checking.\\\\n*   **Potential Fields:** An approach where the robot is attracted to the goal and repelled by obstacles. While intuitive, it can suffer from local minima.\\\\n\\\\n## Motion Planning Algorithms\\\\n\\\\nMotion planning algorithms generate a sequence of valid robot configurations (a path or trajectory) from a start to a goal state, avoiding collisions and respecting robot constraints.\\\\n\\\\n*   **Sampling-based Planners:** These algorithms explore the C-space by randomly sampling configurations and connecting them to build a graph or tree. They are often probabilistically complete (guaranteed to find a path if one exists, given enough time).\\\\n    *   **Rapidly-exploring Random Tree (RRT):** Builds a tree by incrementally extending random samples towards unexplored regions of the C-space. Popular for its efficiency in high-dimensional spaces.\\\\n    *   **Probabilistic Roadmap (PRM):** Constructs a roadmap (graph) by connecting randomly sampled valid configurations. Once the roadmap is built, pathfinding becomes a graph search problem (e.g., Dijkstra\\\\\'s or A\\\\*).\\\\n\\\\n*   **Search-based Planners:** These algorithms discretize the C-space into a grid and search for a path using graph search algorithms.\\\\n    *   **A\\\\* Search:** Finds the shortest path on a graph using a heuristic to guide the search towards the goal.\\\\n    *   **Dijkstra\\\\\'s Algorithm:** Finds the shortest path between nodes in a graph, but without a heuristic, making it slower than A\\\\* for large graphs.\\\\n\\\\n## Navigation in Complex Environments\\\\n\\\\nNavigation involves the continuous process of localization (knowing where the robot is), mapping (creating a representation of the environment), and path planning.\\\\n\\\\n*   **Simultaneous Localization and Mapping (SLAM):** As discussed in Chapter 4, SLAM is critical for robots operating in unknown environments. It allows the robot to build a map while simultaneously figuring out its location within that map.\\\\n*   **Global Path Planning:** Generates an optimal or near-optimal path from the start to the goal using a complete map of the environment. This path is then followed by a local planner.\\\\n*   **Local Path Planning (Obstacle Avoidance):** Operates in real-time using local sensor data to react to unmapped obstacles or dynamic changes in the environment, making small adjustments to the global path.\\\\n\\\\n## Integration with ROS Navigation Stack\\\\n\\\\nROS provides a powerful and modular **Navigation Stack** that offers a complete solution for robot navigation, including global and local planning, costmap generation, and localization.\\\\n\\\\n**Key Components of ROS Navigation Stack:**\\\\n\\\\n*   **move_base:** The primary ROS node that ties together global planning, local planning, and recovery behaviors.\\\\n*   **amcl (Adaptive Monte Carlo Localization):** A probabilistic localization system for a robot moving in a 2D occupancy grid map.\\\\n*   **gmapping:** A ROS package that provides a SLAM algorithm (based on Rao-Blackwellized particle filters) to create 2D occupancy grid maps from laser scans.\\\\n*   **Costmaps:** 2D or 3D grids that represent the cost of traversing each cell, incorporating information about obstacles, inflation layers (to keep the robot away from obstacles), and unknown areas.\\\\n*   **Global Planners (e.g., global_planner, dijkstra_planner):** Compute a path from the start to goal using the entire costmap.\\\\n*   **Local Planners (e.g., dwa_local_planner, teb_local_planner):** Generate velocity commands to follow the global path and avoid local obstacles.\\\\n\\\\n**Example: ROS Navigation Stack Launch File Snippet (XML)**\\\\n\\\\nThis is a simplified move_base launch file. In a full system, you would have separate launch files for your robot model, sensor configurations, and specific planner parameters.\\\\n\\\\nxml\\\\n\x3c!-- move_base.launch --\x3e\\\\n<launch>\\\\n  <node pkg=\\\\\\"move_base\\\\\\" type=\\\\\\"move_base\\\\\\" respawn=\\\\\\"false\\\\\\" name=\\\\\\"move_base\\\\\\" output=\\\\\\"screen\\\\\\">\\\\n    <param name=\\\\\\"base_global_planner\\\\\\" value=\\\\\\"global_planner/GlobalPlanner\\\\\\" />\\\\n    <param name=\\\\\\"base_local_planner\\\\\\" value=\\\\\\"dwa_local_planner/DWAPlannerROS\\\\\\" />\\\\n\\\\n    \x3c!-- Load costmap parameters --\x3e\\\\n    <rosparam file=\\\\\\"$(find my_robot_nav)/config/costmap_common_params.yaml\\\\\\" command=\\\\\\"load\\\\\\" ns=\\\\\\"global_costmap\\\\\\" />\\\\n    <rosparam file=\\\\\\"$(find my_robot_nav)/config/costmap_common_params.yaml\\\\\\" command=\\\\\\"load\\\\\\" ns=\\\\\\"local_costmap\\\\\\" />\\\\n    <rosparam file=\\\\\\"$(find my_robot_nav)/config/global_costmap_params.yaml\\\\\\" command=\\\\\\"load\\\\\\" />\\\\n    <rosparam file=\\\\\\"$(find my_robot_nav)/config/local_costmap_params.yaml\\\\\\" command=\\\\\\"load\\\\\\" />\\\\n\\\\n    \x3c!-- Load planner parameters --\x3e\\\\n    <rosparam file=\\\\\\"$(find my_robot_nav)/config/base_local_planner_params.yaml\\\\\\" command=\\\\\\"load\\\\\\" />\\\\n    <rosparam file=\\\\\\"$(find my_robot_nav)/config/global_planner_params.yaml\\\\\\" command=\\\\\\"load\\\\\\" />\\\\n  </node>\\\\n</launch>\\\\n\\\\n\\\\nThis example shows how move_base integrates different planners and costmaps. The my_robot_nav/config directory would contain .yaml files defining the specific parameters for the costmaps and planners.\\\\n\\\\nPath planning and navigation are essential for enabling humanoid robots to achieve complex goals autonomously and safely in real-world environments.\\\\n","permalink":"/humanoid-robot-book/docs/path-planning/"}}');var a=o(4848),i=o(8453);const r={},s="05 - Actuation and Control",l={},c=[{value:"Motor Control Strategies",id:"motor-control-strategies",level:2},{value:"Joint Space vs. Task Space Control",id:"joint-space-vs-task-space-control",level:2},{value:"Walking and Balance Control",id:"walking-and-balance-control",level:2},{value:"ROS-based Control Examples with Simulated Robots",id:"ros-based-control-examples-with-simulated-robots",level:2}];function d(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"05---actuation-and-control",children:"05 - Actuation and Control"})}),"\n",(0,a.jsx)(e.p,{children:"The ability of a humanoid robot to move gracefully, maintain balance, and interact with its environment stems from sophisticated actuation and control systems. This chapter dives into the mechanisms that translate high-level commands into physical motion."}),"\n",(0,a.jsx)(e.h2,{id:"motor-control-strategies",children:"Motor Control Strategies"}),"\n",(0,a.jsx)(e.p,{children:"Precise control of individual motors is fundamental to achieving desired robot movements. Several strategies are employed:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"PID (Proportional-Integral-Derivative) Control:"}),' A widely used feedback control loop that calculates an "error" value as the difference between a desired setpoint and a measured process variable. The controller attempts to minimize the error by adjusting the control output.']}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"P (Proportional):"})," Responds to the current error."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"I (Integral):"})," Addresses accumulated past errors."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"D (Derivative):"})," Predicts future errors based on the rate of change."]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"PID controllers are often tuned to achieve a balance between responsiveness, overshoot, and stability."}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Impedance Control:"})," A control strategy that regulates the mechanical impedance (relationship between force and motion) of the robot's end-effector. Instead of precisely controlling position or force, it controls how the robot 'reacts' to external forces. This is crucial for compliant interaction with humans or unknown environments, allowing the robot to yield gracefully to contact."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Admittance Control:"})," Similar to impedance control, but it works by mapping external forces sensed by the robot into desired motion commands. If an external force pushes the robot, admittance control determines how much the robot should move in response."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"joint-space-vs-task-space-control",children:"Joint Space vs. Task Space Control"}),"\n",(0,a.jsx)(e.p,{children:"Robot control can be formulated in different conceptual spaces:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Joint Space Control:"})," Commands are directly given in terms of desired joint angles, velocities, or torques. This is simpler to implement for individual joints but can make it difficult to achieve desired end-effector trajectories in Cartesian space."]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.em,{children:"Example:"}),' "Move joint 3 to 90 degrees."']}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Task Space Control (Cartesian Space Control):"})," Commands are given in terms of desired position and orientation of the end-effector (e.g., the robot's hand or foot) in 3D space. The control system then uses inverse kinematics (and Jacobian matrices for velocity/force control) to determine the necessary joint commands."]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.em,{children:"Example:"}),' "Move the right hand to (X, Y, Z) position with a specific orientation."']}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Task space control is more intuitive for human operators and for performing tasks in the real world, but it is computationally more intensive."}),"\n",(0,a.jsx)(e.h2,{id:"walking-and-balance-control",children:"Walking and Balance Control"}),"\n",(0,a.jsx)(e.p,{children:"Bipedal locomotion is one of the most challenging aspects of humanoid robotics, requiring sophisticated control algorithms to maintain balance and achieve stable walking."}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Zero Moment Point (ZMP):"})," A fundamental concept in bipedal locomotion. The ZMP is the point on the ground where the total moment of all forces acting on the robot (including gravity and inertial forces) is zero. For stable walking, the ZMP must remain within the robot's support polygon (the area on the ground enclosed by the feet in contact)."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Capture Point:"})," An extension of ZMP, the Capture Point is a dynamic stability criterion that predicts where the robot would need to step to instantaneously stop its fall. Controlling the Capture Point allows for more dynamic and robust walking, even over uneven terrain."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Model Predictive Control (MPC):"})," An advanced control strategy that uses a dynamic model of the robot to predict its future behavior and optimize control inputs over a receding horizon. MPC is very effective for dynamic balance and trajectory generation in complex systems like humanoids."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"ros-based-control-examples-with-simulated-robots",children:"ROS-based Control Examples with Simulated Robots"}),"\n",(0,a.jsx)(e.p,{children:"ROS (Robot Operating System) provides powerful tools and frameworks for robot control, especially with simulation environments like Gazebo and motion planning libraries like MoveIt."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Example: Basic Joint Control in Gazebo (ROS Python Script)"})}),"\n",(0,a.jsxs)(e.p,{children:["This example demonstrates how to control a simulated robot joint (e.g., ",(0,a.jsx)(e.code,{children:"joint_1"}),") in Gazebo using ROS topics. It assumes a simulated robot is running in Gazebo with ",(0,a.jsx)(e.code,{children:"ros_control"})," set up for joint position interfaces."]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python\n\nimport rospy\nfrom std_msgs.msg import Float64\nimport time\n\ndef joint_controller():\n    rospy.init_node('simple_joint_controller', anonymous=True)\n    # Publisher to command a joint. Replace /robot_name/joint_1_controller/command with your actual topic\n    joint_pub = rospy.Publisher('/my_humanoid/joint_1_controller/command', Float64, queue_size=10)\n\n    rospy.loginfo(\"Waiting for joint controller publisher...\")\n    time.sleep(1) # Give some time for the publisher to connect\n\n    rate = rospy.Rate(1) # 1 Hz\n\n    joint_position = 0.0\n    increment = 0.5\n    max_pos = 1.57 # ~90 degrees\n    min_pos = -1.57 # ~-90 degrees\n\n    while not rospy.is_shutdown():\n        rospy.loginfo(f\"Setting joint_1 position to: {joint_position:.2f}\")\n        joint_pub.publish(joint_position)\n\n        joint_position += increment\n\n        if joint_position > max_pos or joint_position < min_pos:\n            increment *= -1 # Reverse direction\n            joint_position += 2 * increment # Correct position after reversal\n\n        rate.sleep()\n\nif __name__ == '__main__':\n    try:\n        joint_controller()\n    except rospy.ROSInterruptException:\n        pass\n"})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"To run this example, you would typically:"})}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:"Have a Docusaurus-compatible robot model (URDF) loaded in Gazebo."}),"\n",(0,a.jsxs)(e.li,{children:["Have ",(0,a.jsx)(e.code,{children:"ros_control"})," set up with a ",(0,a.jsx)(e.code,{children:"JointPositionController"})," for ",(0,a.jsx)(e.code,{children:"joint_1"})," (defined in a ",(0,a.jsx)(e.code,{children:"controllers.yaml"})," and loaded via a launch file)."]}),"\n",(0,a.jsxs)(e.li,{children:["Run ",(0,a.jsx)(e.code,{children:"roscore"}),"."]}),"\n",(0,a.jsxs)(e.li,{children:["Launch your robot in Gazebo: ",(0,a.jsx)(e.code,{children:"roslaunch my_robot_gazebo my_robot.launch"})]}),"\n",(0,a.jsxs)(e.li,{children:["Launch the controller: ",(0,a.jsx)(e.code,{children:"roslaunch my_robot_control my_robot_control.launch"})]}),"\n",(0,a.jsxs)(e.li,{children:["Run this Python script: ",(0,a.jsx)(e.code,{children:"rosrun your_package simple_joint_controller.py"})]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"These control strategies, combined with robust actuation, allow humanoid robots to execute a wide array of complex physical tasks, from simple movements to dynamic walking and interaction."})]})}function h(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}}}]);